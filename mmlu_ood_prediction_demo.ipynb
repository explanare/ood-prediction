{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOmErTjseo8DtAJfrRRDRSh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/explanare/ood-prediction/blob/main/mmlu_ood_prediction_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "SYrNYwXfgslY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flbgMtAlcLn1"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "\n",
        "#@markdown **[Run this block]**\n",
        "\n",
        "#@markdown Set up environment.\n",
        "\n",
        "#@markdown Set the absolute path to ood-prediction.\n",
        "project_dir = '/path/to/ood-prediction' #@param\n",
        "DATA_DIR = f'{project_dir}/data'\n",
        "MODEL_DIR = f'{project_dir}/models'\n",
        "\n",
        "sys.path.append(f'{project_dir}/src')\n",
        "#@markdown Set the Huggingface home/caching dir.\n",
        "hf_home = '/path/to/hf_home'  #@param\n",
        "os.environ[\"HF_HOME\"] = hf_home\n",
        "os.environ[\"HF_HUB\"] = hf_home\n",
        "os.environ[\"TRANSFORMERS_CACHE\"] = hf_home\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(0)\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "kyAKTZwbNoMb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Target Model\n",
        "\n",
        "In our experiment, we are interested in predicting the correctness of outputs from `Llama-3-8B-Instruct`."
      ],
      "metadata": {
        "id": "9WrnFvUumZZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Llama3 is a gated model. You may need to log in to your HuggingFace account to\n",
        "# access this model.\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "A9PsTSvHqDP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **[Run this block]**\n",
        "\n",
        "#@markdown Load `meta-llama/Meta-Llama-3-8B-Instruct` from HuggingFace Hub.\n",
        "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "\n",
        "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id, low_cpu_mem_usage=True, device_map='auto',\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    )\n",
        "model = model.eval()\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = 'left'"
      ],
      "metadata": {
        "id": "hHMdtbJZmUf5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Correctness Prediction Task"
      ],
      "metadata": {
        "id": "Pu-uQWiUhf1e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are interested in predicting whether a target model\n",
        "produces correct answers on a task, espeically on out-of-distribution inputs.\n",
        "\n",
        "For example, consider the following multiple-choice question from MMLU test set.\n",
        "\n",
        "```\n",
        "The following are multiple choice questions (with answers) about abstract algebra.\n",
        "\n",
        "Find the degree for the given field extension Q(sqrt(2), sqrt(3), sqrt(18)) over Q.\n",
        "\n",
        "A. 0\n",
        "B. 4\n",
        "C. 2\n",
        "D. 6\n",
        "\n",
        "Answer:\n",
        "```\n",
        "\n",
        "If we prompt the target model with this question and the model outputs `B`, how do we know if the model prediction is correct?\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "### Dataset Construction\n",
        "\n",
        "To formalize this correctness prediction task, we first run behavioral testing on the target model to produce a correctness prediction dataset.\n",
        "\n",
        "* **ID splits**: Randomly sampled 2048/1024/1024 examples as train/val/test sets from the MMLU test split. For each set, half of the examples are correctly predicted by the target model.\n",
        "\n",
        "* **OOD splits**: Randomly sampled 512 correct and 512 wrong examples from a modified version of MMLU test split, where either (1) the options (i.e., A, B, C, D) are changed to a different alphabet, or (2) a distracting option E is added to the options.\n",
        "\n",
        "Below is an OOD example:\n",
        "\n",
        "```\n",
        "The following are multiple choice questions (with answers) about abstract algebra.\n",
        "\n",
        "Find the degree for the given field extension Q(sqrt(2), sqrt(3), sqrt(18)) over Q.\n",
        "\n",
        "Alpha. 0\n",
        "Beta. 4\n",
        "Charlie. 2\n",
        "Delta. 6\n",
        "\n",
        "Answer:\n",
        "```\n",
        "\n",
        "\n",
        "We provide the pre-generated dataset at https://github.com/explanare/ood-prediction/tree/main/data/mmlu_task"
      ],
      "metadata": {
        "id": "ZDGKDF6NhmLV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method I: Confidence Scores"
      ],
      "metadata": {
        "id": "_Lyv_2wkgxK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **[Run this block]**\n",
        "\n",
        "#@markdown Predict correctness using confidence scores.\n",
        "\n",
        "import collections\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "from generation_utils import generate_batched\n",
        "from metrics import compute_confidence_score, pool_confidence_score, compute_per_token_loss_batched\n",
        "\n",
        "\n",
        "MMLU_SPLITS = ['in_distribution', 'ood-nato-label', 'ood-e-correct-answer-is-a']\n",
        "\n",
        "setting_to_metrics = collections.defaultdict(lambda: collections.defaultdict(list))\n",
        "split_type = 'ood-nato-label' # one of MMLU_SPLITS\n",
        "task = 'mmlu'  # one of ['mmlu', 'mmlu-mixed]; 'mmlu-mixed' evaluate all splits together without per-split calibration.\n",
        "split = 'test'\n",
        "for fold in range(3):\n",
        "  if task == 'mmlu':\n",
        "    data_split = json.load(open(os.path.join(DATA_DIR, 'mmlu_task', f'mmlu_{model.name_or_path.split(\"/\")[-1]}_no_chat_template_0shot_{split_type}_split_{fold}.json')))\n",
        "  elif task == 'mmlu-mixed':\n",
        "    data_split = json.load(open(os.path.join(DATA_DIR, 'mmlu_task', f'mmlu_{model.name_or_path.split(\"/\")[-1]}_no_chat_template_0shot_{MMLU_SPLITS[0]}_split_{fold}.json')))\n",
        "    for i in range(1, 3):\n",
        "      ood_data = json.load(open(os.path.join(DATA_DIR, 'mmlu_task', f'mmlu_{model.name_or_path.split(\"/\")[-1]}_no_chat_template_0shot_{MMLU_SPLITS[i]}_split_{fold}.json')))\n",
        "      for s in ood_data:\n",
        "        for k in ood_data[s]:\n",
        "          data_split[s][k] += ood_data[s][k]\n",
        "  prompt_to_output = generate_batched(\n",
        "      model, tokenizer, data_split[split]['correct'] + data_split[split]['wrong'],\n",
        "      max_new_tokens=1, batch_size=8, top_p=None, top_k=None, temperature=None)\n",
        "  test_prompt_batch = data_split[split]['correct'] + data_split[split]['wrong']\n",
        "  test_output_batch = [prompt_to_output[p] for p in test_prompt_batch]\n",
        "  for temp in np.arange(0.5, 5.0, 0.5):\n",
        "    confidence_score = compute_confidence_score(\n",
        "          model, tokenizer, test_prompt_batch, test_output_batch,\n",
        "          score_fn=lambda x: pool_confidence_score(tokenizer, x, next_n_tokens=1, mode='mean'),\n",
        "          max_length=512,\n",
        "          batch_size=8,\n",
        "          temperature=temp)\n",
        "    pred_data = pd.DataFrame([{'compare_correct': i < len(data_split[split]['correct']),\n",
        "                               'top1_confidence': x} for i, x in enumerate(confidence_score)])\n",
        "    auc_roc = roc_auc_score(pred_data['compare_correct'].tolist(), pred_data['top1_confidence'].tolist())\n",
        "    setting_to_metrics[temp]['auc_roc'].append(auc_roc)"
      ],
      "metadata": {
        "id": "XaSmQARUhfFe",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first use **in-distribution**, **validation** set to determine the optimal temerpature (i.e., the hyperparameter)\n",
        "\n",
        "Below are the results. We search in the range of 0.5 to 4.5, which is a broader range than we used in the paper. We see that AUC-ROC peaks at **T=1.5**.\n",
        "\n",
        "|Temperature| AUC-ROC Mean | STD |\n",
        "|:-:|:-:|:-:|\n",
        "| T=0.5\t| 0.7963\t| 0.0103 |\n",
        "| T=1.0\t| 0.8211\t| 0.0066 |\n",
        "| **T=1.5**\t| **0.8220**\t| 0.0040 |\n",
        "| T=2.0\t| 0.8139\t| 0.0029 |\n",
        "| T=2.5\t| 0.8045\t| 0.0032 |\n",
        "| T=3.0\t| 0.8022\t| 0.0037 |\n",
        "| T=3.5\t| 0.8022\t| 0.0041 |\n",
        "| T=4.0\t| 0.8023\t| 0.0040 |\n",
        "\n",
        "When evaluate on the **in-distribution**, **test set**  split, using the best temperature on validation set, i.e., **T=1.5**, the AUC-ROC is **0.8078**. The full results are below.\n",
        "\n",
        "|Temperature| AUC-ROC Mean | STD |\n",
        "|:-:|:-:|:-:|\n",
        "| T=0.5\t| 0.7854\t| 0.0102 |\n",
        "| T=1.0\t| 0.8099\t| 0.0093 |\n",
        "| **T=1.5**\t| **0.8078**\t| 0.0071 |\n",
        "| T=2.0\t| 0.7952\t| 0.0017 |\n",
        "| T=2.5\t| 0.7854\t| 0.0004 |\n",
        "| T=3.0\t| 0.7834\t| 0.0013 |\n",
        "| T=3.5\t| 0.7835\t| 0.0011 |\n",
        "| T=4.0\t| 0.7837\t| 0.0012 |"
      ],
      "metadata": {
        "id": "Eq4UJQSbkLQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **[Run this block]**\n",
        "\n",
        "#@markdown Now we evaluate on the OOD split. Based on our hyperparameter search results on the validation set, we use **T=1.5**, which yeilds a mean AUC-ROC of **0.747**.\n",
        "\n",
        "#@markdown We can see the effects of distribution shift on correctness prediction accuracy. The correctness prediction AUC-ROC actually peaks at T=3.5, however, this AUC-ROC is only achievable if we have access to labeled OOD data.\n",
        "\n",
        "print('Split Name\\tTemp\\tMean\\tSTD')\n",
        "for t in setting_to_metrics:\n",
        "  print(split_type, f'T={t}\\t' + '%.4f\\t%.4f' % (np.mean(setting_to_metrics[t]['auc_roc']), np.std(setting_to_metrics[t]['auc_roc'])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a2c8511-72a5-4da3-d28f-9ec31f40c0cd",
        "cellView": "form",
        "id": "bJn72-3k4VYh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split Name\tTemp\tMean\tSTD\n",
            "ood-nato-label T=0.5\t0.6714\t0.0233\n",
            "ood-nato-label T=1.0\t0.7071\t0.0214\n",
            "ood-nato-label T=1.5\t0.7466\t0.0182\n",
            "ood-nato-label T=2.0\t0.7612\t0.0165\n",
            "ood-nato-label T=2.5\t0.7627\t0.0163\n",
            "ood-nato-label T=3.0\t0.7631\t0.0165\n",
            "ood-nato-label T=3.5\t0.7632\t0.0167\n",
            "ood-nato-label T=4.0\t0.7630\t0.0161\n",
            "ood-nato-label T=4.5\t0.7624\t0.0164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method II: Counterfactual Simulation"
      ],
      "metadata": {
        "id": "QANEoRyJg0nH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This method is implemented using [pyvene](https://github.com/stanfordnlp/pyvene).\n",
        "\n",
        "You can download pyvene using\n",
        "\n",
        "`git clone https://github.com/stanfordnlp/pyvene.git`\n"
      ],
      "metadata": {
        "id": "5ELylXR6PYwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **[Run this block]**\n",
        "\n",
        "#@markdown Once `pyvene` is downloaded, update the absolute path to pyvene below.\n",
        "\n",
        "import sys\n",
        "\n",
        "pyvene_abs_path = '/path/to/pyvene' #@param\n",
        "sys.path.append(pyvene_abs_path)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xvkq9F8wqWnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training (Localizing high-level variables)\n",
        "\n",
        "This section uses Distributed Alignment Search (DAS) to localize the intermediate high-level variable, i.e., a **pointer** to the selected option, on a verified set.\n",
        "\n",
        "**You can skip to the [inference section](#scrollTo=6i41RAOXQbHO) by using the pre-computed localization results provided in the repo.**"
      ],
      "metadata": {
        "id": "21qijyTZQcrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **[Run this block]**\n",
        "\n",
        "#@markdown Task-specific helper function\n",
        "\n",
        "CHOICES = ['A', 'B', 'C', 'D']\n",
        "\n",
        "SYMBOL_MAPPING = {\n",
        "    c: CHOICES\n",
        "    for c in CHOICES\n",
        "}\n",
        "\n",
        "\n",
        "def extract_prediction(topk_prob):\n",
        "  choice_to_prob = {}\n",
        "  for c in CHOICES:\n",
        "    ans_dist = [x[1] for x in topk_prob if x[0].strip() == c]\n",
        "    choice_to_prob[c] = sum(ans_dist, 0)\n",
        "  return sorted(choice_to_prob, key=choice_to_prob.get, reverse=True)[0]"
      ],
      "metadata": {
        "id": "erkYr353SeMH",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **[Run this block]**\n",
        "\n",
        "#@markdown Load training data\n",
        "\n",
        "import json\n",
        "\n",
        "from causal_data_utils import load_intervention_data, _BASE_TEMPLATE\n",
        "from generation_utils import generate_batched, generate_distribution_batched\n",
        "\n",
        "sample_size = 1024\n",
        "# We only run localization on in-distribution data.\n",
        "split_type = 'in_distribution'\n",
        "FOLD_ID = '0' #@param\n",
        "mode = 'das'\n",
        "data_split = json.load(open(os.path.join(\n",
        "    DATA_DIR, 'mmlu_task', f'mmlu_Meta-Llama-3-8B-Instruct_no_chat_template_0shot_in_distribution_split_{FOLD_ID}.json')))\n",
        "verified_examples = data_split['train']['correct'][:sample_size]\n",
        "print('Verified Examples:')\n",
        "print(verified_examples[0])\n",
        "\n",
        "prompts =  [x for s in data_split for c in data_split[s] for x in data_split[s][c]]\n",
        "intervention_prompt_to_output = generate_distribution_batched(\n",
        "      model, tokenizer, prompts, top_k=50)\n",
        "intervention_prompt_to_output = dict(zip(prompts, intervention_prompt_to_output))\n",
        "intervention_prompt_to_output = {k: extract_prediction(v) for k, v in intervention_prompt_to_output.items()}\n",
        "prompt_to_vars = {p: {'input': p,\n",
        "                      'label': ' ' + intervention_prompt_to_output[p],\n",
        "                      'split': _BASE_TEMPLATE}\n",
        "                 for s in data_split for k in ('correct', 'wrong') for p in data_split[s][k]}\n",
        "\n",
        "\n",
        "def convert_label(base, source):\n",
        "  base_label = base['label'].strip()\n",
        "  source_label = source['label'].strip()\n",
        "  source_index = SYMBOL_MAPPING[source_label].index(source_label)\n",
        "  return ' ' + SYMBOL_MAPPING[base_label][source_index]\n",
        "\n",
        "\n",
        "split_to_raw_example, split_to_dataset = load_intervention_data(\n",
        "    mode, verified_examples, data_split, prompt_to_vars,\n",
        "    inv_label_fn=convert_label,\n",
        "    filter_fn=lambda x, y: True,\n",
        "    max_example_per_split=20480,\n",
        "    max_example_per_eval_split=10)"
      ],
      "metadata": {
        "id": "cd9FyPTmQewH",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown **[Run this block]**\n",
        "\n",
        "# @markdown Run DAS to localize a subspace.\n",
        "\n",
        "import collections\n",
        "import gc\n",
        "\n",
        "from causal_interventions import (\n",
        "  LowRankRotatedSpaceIntervention,\n",
        "  compute_metrics,\n",
        "  eval_with_interventions_batched,\n",
        "  get_intervention_config,\n",
        "  remove_all_forward_hooks,\n",
        "  remove_invalid_token_id,\n",
        "  train_intervention_step,\n",
        ")\n",
        "from causal_data_utils import (\n",
        "    _BASE_TEMPLATE,\n",
        "    _SOURCE_TEMPLATE,\n",
        "    get_dataloader\n",
        ")\n",
        "import pyvene as pv\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from tqdm import tqdm, trange\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "def compute_cross_entropy_loss(logits, labels, pad_token_id, next_n_tokens=1):\n",
        "  \"\"\"Computes cross-entropy loss over the last n tokens.\"\"\"\n",
        "  vocab_size = logits.shape[-1]\n",
        "  labels = labels.clone()\n",
        "  shift_logits = logits[..., -next_n_tokens - 1 : -1, :].contiguous()\n",
        "  shift_labels = labels[..., -next_n_tokens:].contiguous()\n",
        "  shift_logits = shift_logits.view(-1, vocab_size)\n",
        "  shift_labels = shift_labels.view(-1)\n",
        "  shift_labels = shift_labels.to(shift_logits.device)\n",
        "  shift_labels[shift_labels == pad_token_id] = -100\n",
        "  loss = CrossEntropyLoss()(shift_logits, shift_labels)\n",
        "  return loss\n",
        "\n",
        "\n",
        "def train_alignment(config):\n",
        "  print(\"#Training examples: %d\" % len(split_to_dataset[\"das-train\"]))\n",
        "  max_train_example = int(\n",
        "    config[\"max_train_percentage\"] * len(split_to_dataset[\"das-train\"])\n",
        "  )\n",
        "  train_dataloader = get_dataloader(\n",
        "    split_to_dataset[\"das-train\"].select(range(max_train_example)),\n",
        "    tokenizer=tokenizer,\n",
        "    batch_size=TRAINING_BATCH_SIZE,\n",
        "    prompt_max_length=INPUT_MAX_LEN,\n",
        "    output_max_length=config[\"max_output_tokens\"]\n",
        "    + int(tokenizer.bos_token is not None),\n",
        "    first_n=config[\"max_output_tokens\"],\n",
        "  )\n",
        "\n",
        "  # Create Model\n",
        "  split_to_inv_locations = config[\"split_to_inv_locations\"]\n",
        "  intervenable_config = get_intervention_config(\n",
        "    type(model),\n",
        "    config[\"intervenable_config\"][\"intervenable_representation_type\"],\n",
        "    [config[\"intervenable_config\"][\"intervenable_layer\"]],\n",
        "    config[\"intervenable_config\"][\"intervenable_interventions_type\"],\n",
        "    intervention_dimension=config[\"intervention_dimension\"],\n",
        "  )\n",
        "  intervenable = pv.IntervenableModel(intervenable_config, model)\n",
        "  intervenable.set_device(\"cuda\")\n",
        "  intervenable.disable_model_gradients()\n",
        "\n",
        "  # Training\n",
        "  epochs = config[\"training_epoch\"]\n",
        "  gradient_accumulation_steps = 1\n",
        "  total_step = 0\n",
        "\n",
        "  warm_up_steps = 0\n",
        "  optimizer_params = []\n",
        "  for k, v in intervenable.interventions.items():\n",
        "    if isinstance(v[0], LowRankRotatedSpaceIntervention):\n",
        "      optimizer_params += [{\"params\": v[0].rotate_layer.parameters()}]\n",
        "    else:\n",
        "      raise NotImplementedError\n",
        "  optimizer = torch.optim.AdamW(\n",
        "    optimizer_params, lr=config[\"init_lr\"], weight_decay=0\n",
        "  )\n",
        "  scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=warm_up_steps,\n",
        "    num_training_steps=int(10 * len(train_dataloader)),\n",
        "  )\n",
        "\n",
        "  print(\n",
        "    \"base model trainable parameters: \", pv.count_parameters(intervenable.model)\n",
        "  )\n",
        "  print(\"intervention trainable parameters: \", intervenable.count_parameters())\n",
        "  train_iterator = trange(0, int(epochs), desc=\"Epoch\")\n",
        "\n",
        "  num_output_tokens = config[\"max_output_tokens\"]\n",
        "  for epoch in train_iterator:\n",
        "    epoch_iterator = tqdm(\n",
        "      train_dataloader, desc=f\"Epoch: {epoch}\", position=0, leave=True\n",
        "    )\n",
        "    aggreated_stats = collections.defaultdict(list)\n",
        "    for step, inputs in enumerate(epoch_iterator):\n",
        "      for k, v in inputs.items():\n",
        "        if v is not None and isinstance(v, torch.Tensor):\n",
        "          inputs[k] = v.to(\"cuda\")\n",
        "      position_ids = {\n",
        "        f\"{prefix}position_ids\": intervenable.model.prepare_inputs_for_generation(\n",
        "          input_ids=inputs[f\"{prefix}input_ids\"],\n",
        "          attention_mask=inputs[f\"{prefix}attention_mask\"],\n",
        "        )[\"position_ids\"]\n",
        "        for prefix in (\"\", \"source_\")\n",
        "      }\n",
        "      inputs.update(position_ids)\n",
        "      for key in inputs:\n",
        "        if key in (\n",
        "          \"input_ids\",\n",
        "          \"source_input_ids\",\n",
        "          \"attention_mask\",\n",
        "          \"source_attention_mask\",\n",
        "          \"position_ids\",\n",
        "          \"source_position_ids\",\n",
        "        ):\n",
        "          inputs[key] = inputs[key].to(device)\n",
        "\n",
        "      counterfactual_outputs = train_intervention_step(\n",
        "        intervenable,\n",
        "        inputs,\n",
        "        split_to_inv_locations,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "      )\n",
        "      eval_metrics = compute_metrics(\n",
        "        {\n",
        "          \"inv_outputs\": [\n",
        "            counterfactual_outputs.logits[:, -num_output_tokens - 1 : -1]\n",
        "          ]\n",
        "        },\n",
        "        [inputs[\"labels\"][:, :num_output_tokens]],\n",
        "        last_n_tokens=num_output_tokens,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "      )\n",
        "      loss = compute_cross_entropy_loss(\n",
        "        counterfactual_outputs.logits,\n",
        "        inputs[\"labels\"][:, :num_output_tokens],\n",
        "        next_n_tokens=num_output_tokens,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "      )\n",
        "      aggreated_stats[\"loss\"].append(loss.item())\n",
        "      aggreated_stats[\"acc\"].append(eval_metrics[\"inv_outputs\"][\"accuracy\"])\n",
        "      epoch_iterator.set_postfix(\n",
        "        {k: round(np.mean(aggreated_stats[k]), 2) for k in aggreated_stats}\n",
        "      )\n",
        "\n",
        "      if step < 3:\n",
        "        print(\"\\nTokens to intervene:\")\n",
        "        intervention_locations = [\n",
        "          split_to_inv_locations[inputs[\"split\"][i]][\"inv_position\"]\n",
        "          for i in range(len(inputs[\"split\"]))\n",
        "        ]\n",
        "        source_intervention_locations = [\n",
        "          split_to_inv_locations[inputs[\"source_split\"][i]][\"inv_position\"]\n",
        "          for i in range(len(inputs[\"split\"]))\n",
        "        ]\n",
        "        print(inputs[\"input\"][:3])\n",
        "        print(inputs[\"source_input\"][:3])\n",
        "        print(\n",
        "          \"Base:\",\n",
        "          tokenizer.batch_decode(\n",
        "            [\n",
        "              inputs[\"input_ids\"][i][intervention_locations[i]]\n",
        "              for i in range(len(inputs[\"split\"]))\n",
        "            ]\n",
        "          ),\n",
        "        )\n",
        "        print(\n",
        "          \"Source:\",\n",
        "          tokenizer.batch_decode(\n",
        "            [\n",
        "              inputs[\"source_input_ids\"][i][source_intervention_locations[i]]\n",
        "              for i in range(len(inputs[\"split\"]))\n",
        "            ]\n",
        "          ),\n",
        "        )\n",
        "        print(\n",
        "          \"Output:\",\n",
        "          tokenizer.batch_decode(\n",
        "            torch.argmax(\n",
        "              counterfactual_outputs.logits[:, -num_output_tokens - 1 : -1],\n",
        "              dim=-1,\n",
        "            )\n",
        "          ),\n",
        "        )\n",
        "        print(\n",
        "          \"Label     :\",\n",
        "          tokenizer.batch_decode(\n",
        "            remove_invalid_token_id(\n",
        "              inputs[\"labels\"][:, :num_output_tokens], tokenizer.pad_token_id\n",
        "            )\n",
        "          ),\n",
        "        )\n",
        "        print(\n",
        "          \"Base Label:\",\n",
        "          tokenizer.batch_decode(\n",
        "            remove_invalid_token_id(\n",
        "              inputs[\"base_labels\"][:, :num_output_tokens],\n",
        "              tokenizer.pad_token_id,\n",
        "            )\n",
        "          ),\n",
        "        )\n",
        "\n",
        "      if gradient_accumulation_steps > 1:\n",
        "        loss = loss / gradient_accumulation_steps\n",
        "      if total_step % gradient_accumulation_steps == 0:\n",
        "        if not (gradient_accumulation_steps > 1 and total_step == 0):\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          scheduler.step()\n",
        "          intervenable.set_zero_grad()\n",
        "      total_step += 1\n",
        "  return intervenable, intervenable_config\n",
        "\n",
        "\n",
        "def run_exp(config):\n",
        "  task_name = \"mmlu\"\n",
        "  split_to_inv_locations = config[\"split_to_inv_locations\"]\n",
        "  input_len = list(split_to_inv_locations.values())[0][\"max_input_length\"]\n",
        "  inv_pos = min([x[\"inv_position\"][0] for x in split_to_inv_locations.values()])\n",
        "  inv_loc_name = \"len%d-pos%s\" % (\n",
        "    input_len,\n",
        "    \"e\" if inv_pos != input_len - 1 else \"f\",\n",
        "  )\n",
        "  model_name = model.name_or_path.split(\"/\")[-1]\n",
        "  run_name = (\n",
        "    f\"{task_name}-{FOLD_ID}\"\n",
        "    f\"_{model_name}-layer{config['intervenable_config']['intervenable_layer']}\"\n",
        "    f\"-{config['intervenable_config']['intervenable_representation_type']}\"\n",
        "    f\"-dim{config['intervention_dimension']}-{inv_loc_name}\"\n",
        "    f\"_ep{config['training_epoch']}_example{len(verified_examples)}\"\n",
        "  )\n",
        "  config[\"run_name_prefix\"] = run_name\n",
        "  print(run_name)\n",
        "  if True:\n",
        "    print(run_name)\n",
        "    intervenable, intervenable_config = train_alignment(config)\n",
        "    # Save model\n",
        "    torch.save(\n",
        "      {\n",
        "        k: v[0].rotate_layer.weight\n",
        "        for k, v in intervenable.interventions.items()\n",
        "      },\n",
        "      os.path.join(MODEL_DIR, f\"{run_name}.pt\"),\n",
        "    )\n",
        "    print(\"\\nModel saved to %s\" % os.path.join(MODEL_DIR, f\"{run_name}.pt\\n\"))\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    # eval\n",
        "    with torch.no_grad():\n",
        "      split_to_eval_metrics = eval_with_interventions_batched(\n",
        "        intervenable,\n",
        "        eval_split_to_dataset,\n",
        "        split_to_inv_locations,\n",
        "        tokenizer,\n",
        "        compute_metrics_fn=compute_metrics,\n",
        "        max_new_tokens=config[\"max_output_tokens\"],\n",
        "        eval_batch_size=EVAL_BATCH_SIZE,\n",
        "        inference_mode=\"generate\",\n",
        "        debug_print=False,\n",
        "      )\n",
        "    print(\n",
        "      \"Mean IIA: %.4f\"\n",
        "      % np.mean(\n",
        "        [\n",
        "          v[\"metrics\"][\"labels\"][\"inv_outputs\"][\"accuracy\"]\n",
        "          for k, v in split_to_eval_metrics.items()\n",
        "        ]\n",
        "      )\n",
        "    )\n",
        "    print(\n",
        "      \"Mean correct IIA: %.4f\"\n",
        "      % np.mean(\n",
        "        [\n",
        "          v[\"metrics\"][\"labels\"][\"inv_outputs\"][\"accuracy\"]\n",
        "          for k, v in split_to_eval_metrics.items()\n",
        "          if \"-correct\" in k\n",
        "        ]\n",
        "      )\n",
        "    )\n",
        "    print(\n",
        "      \"Mean wrong IIA: %.4f\"\n",
        "      % np.mean(\n",
        "        [\n",
        "          v[\"metrics\"][\"labels\"][\"inv_outputs\"][\"accuracy\"]\n",
        "          for k, v in split_to_eval_metrics.items()\n",
        "          if \"-wrong\" in k\n",
        "        ]\n",
        "      )\n",
        "    )\n",
        "  remove_all_forward_hooks(intervenable)\n",
        "  return intervenable\n",
        "\n",
        "\n",
        "assert mode == \"das\"\n",
        "\n",
        "INPUT_MAX_LEN = 256  # cover 90%\n",
        "TRAINING_BATCH_SIZE = 16\n",
        "EVAL_BATCH_SIZE = 16\n",
        "BASE_TEMPLATE = _BASE_TEMPLATE\n",
        "SOURCE_TEMPLATE = _SOURCE_TEMPLATE\n",
        "\n",
        "TEMPLATE_TO_INV_LOCATIONS = {\n",
        "  split: {\n",
        "    \"max_input_length\": INPUT_MAX_LEN,\n",
        "    \"inv_position\": [INPUT_MAX_LEN - 1],\n",
        "  }\n",
        "  for split in list(split_to_dataset) + [BASE_TEMPLATE, SOURCE_TEMPLATE]\n",
        "}\n",
        "\n",
        "eval_split_to_dataset = {\n",
        "  k: v for k, v in split_to_dataset.items() if k.endswith(\"-test\")\n",
        "}\n",
        "\n",
        "model = model.eval()\n",
        "\n",
        "\n",
        "for inv_layer in [18]:\n",
        "  for lr in [1e-4]:\n",
        "    for inv_dim in [4]:\n",
        "      config = {\n",
        "        \"intervention_dimension\": inv_dim,\n",
        "        \"max_output_tokens\": 1,\n",
        "        \"intervenable_config\": {\n",
        "          \"intervenable_layer\": inv_layer,\n",
        "          \"intervenable_representation_type\": \"block_output\",\n",
        "          \"intervenable_unit\": \"pos\",\n",
        "          \"max_number_of_units\": 1,\n",
        "          \"intervenable_interventions_type\": LowRankRotatedSpaceIntervention,\n",
        "        },\n",
        "        \"training_epoch\": 1,\n",
        "        \"max_train_percentage\": 1.0,\n",
        "        \"split_to_inv_locations\": TEMPLATE_TO_INV_LOCATIONS,\n",
        "        \"split_to_labels\": None,\n",
        "        \"init_lr\": lr,\n",
        "      }\n",
        "      intervenable = run_exp(config)"
      ],
      "metadata": {
        "id": "ecFtPntjklxm",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "6i41RAOXQbHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **[Run this block]**\n",
        "\n",
        "#@markdown Prepare eval data for the correctness prediction task.\n",
        "\n",
        "import json\n",
        "\n",
        "from causal_data_utils import load_intervention_data, _BASE_TEMPLATE\n",
        "from generation_utils import generate_batched\n",
        "\n",
        "sample_size = 16\n",
        "\n",
        "#@markdown `eval_split` could be one of 'in_distribution', 'ood-nato-label', 'ood-e-correct-answer-is-a', or 'all_splits'.\n",
        "eval_split = 'ood-nato-label'  #@param\n",
        "FOLD_ID = '0'                  #@param\n",
        "mode = 'test'\n",
        "data_split = json.load(open(os.path.join(DATA_DIR, 'mmlu_task', f'mmlu_Meta-Llama-3-8B-Instruct_no_chat_template_0shot_in_distribution_split_{FOLD_ID}.json')))\n",
        "\n",
        "# Setting I: Test each split separately. This is the setting we used in the paper.\n",
        "if eval_split != 'all_splits':\n",
        "  data_split['test'] = json.load(open(os.path.join(DATA_DIR, 'mmlu_task', f'mmlu_{model.name_or_path.split(\"/\")[-1]}_no_chat_template_0shot_{eval_split}_split_{FOLD_ID}.json')))['test']\n",
        "# Setting II: Test all splits together, i.e., mixing the ID and all OOD splits.\n",
        "# This is actually a more challenging setting, especially for methods that do\n",
        "# not handle distribution shifts well.\n",
        "else:\n",
        "  for s in data_split['test']:\n",
        "    data_split['test'][s] += json.load(open(os.path.join(DATA_DIR, 'mmlu_task', f'mmlu_{model.name_or_path.split(\"/\")[-1]}_no_chat_template_0shot_ood-nato-label_split_{FOLD_ID}.json')))['test'][s]\n",
        "    data_split['test'][s] += json.load(open(os.path.join(DATA_DIR, 'mmlu_task', f'mmlu_{model.name_or_path.split(\"/\")[-1]}_no_chat_template_0shot_ood-e-correct-answer-is-a-label_split_{FOLD_ID}.json')))['test'][s]\n",
        "\n",
        "verified_examples = data_split['train']['correct'][:sample_size]\n",
        "print('Verified Examples:')\n",
        "print(verified_examples[0])\n",
        "\n",
        "print('\\nEval Examples:')\n",
        "print(data_split['test']['correct'][0])\n",
        "\n",
        "intervention_prompt_to_output = generate_batched(model, tokenizer, [p for s in data_split for k in ('correct', 'wrong') for p in data_split[s][k]], max_new_tokens=1)\n",
        "prompt_to_vars = {p: {'input': p,\n",
        "                      'label': intervention_prompt_to_output[p],\n",
        "                      'split': _BASE_TEMPLATE}\n",
        "                 for s in data_split for k in ('correct', 'wrong') for p in data_split[s][k]}\n",
        "\n",
        "\n",
        "CHOICES = [\"A\", \"B\", \"C\", \"D\"]\n",
        "OOD_CHOICES = [\"Alfa\", \"Bravo\", \"Charlie\", \"Delta\"]\n",
        "\n",
        "split_to_raw_example, split_to_dataset = load_intervention_data(\n",
        "    mode, verified_examples, data_split, prompt_to_vars,\n",
        "    inv_label_fn=lambda x, y: (' ' + CHOICES[OOD_CHOICES.index(y['label'].strip().replace('Al', 'Alfa'))]) if y['label'].strip().replace('Al', 'Alfa') in OOD_CHOICES else y['label'],\n",
        "    filter_fn=None,\n",
        "    max_example_per_split=20480,\n",
        "    max_example_per_eval_split=10)"
      ],
      "metadata": {
        "id": "B2DNHNwnEArC",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **[Run this block]**\n",
        "\n",
        "#@markdown Run evaluation\n",
        "\n",
        "import re\n",
        "\n",
        "import pyvene as pv\n",
        "from causal_interventions import (\n",
        "    compute_metrics,\n",
        "    compute_logits_metrics,\n",
        "    eval_with_interventions_batched,\n",
        "    load_intervenable,\n",
        "    remove_all_forward_hooks\n",
        ")\n",
        "from causal_data_utils import _BASE_TEMPLATE, _SOURCE_TEMPLATE\n",
        "\n",
        "assert mode == 'test' and len(verified_examples) == 16\n",
        "\n",
        "\n",
        "INPUT_MAX_LEN = 360\n",
        "ckpt_name = f'ood-prediction/models/mmlu-{FOLD_ID}_Meta-Llama-3-8B-Instruct-layer18-block_output-dim4-len256-posf_ep1_example1024.pt' #@param\n",
        "\n",
        "assert f'mmlu-{FOLD_ID}' in ckpt_name\n",
        "\n",
        "inv_locs = {_BASE_TEMPLATE: [INPUT_MAX_LEN - 1],\n",
        "            _SOURCE_TEMPLATE: [INPUT_MAX_LEN - 1]}\n",
        "inv_location_key = None\n",
        "\n",
        "# For testing\n",
        "eval_split_to_dataset = {k: v for k, v in split_to_dataset.items()\n",
        "                         if k.endswith('-test')\n",
        "                         }\n",
        "print(len(eval_split_to_dataset))\n",
        "\n",
        "\n",
        "inference_mode = 'force_decode'\n",
        "MAX_NEW_TOKENS = 1\n",
        "aggregate_n_layers = 1\n",
        "NUM_LAYER = model.config.n_layer if 'gpt2' in model.name_or_path else model.config.num_hidden_layers\n",
        "\n",
        "\n",
        "eval_metrics = {}\n",
        "inv_layer = int(re.search(r'layer(\\d+)-', ckpt_name)[1]) if ckpt_name is not None else None\n",
        "TEMPLATE_TO_INV_LOCATIONS = {\n",
        "    f'{task}': {'max_input_length': INPUT_MAX_LEN,\n",
        "                'inv_position': inv_locs[task],\n",
        "                }\n",
        "    for task in inv_locs\n",
        "}\n",
        "if ckpt_name is None:\n",
        "  if inv_location_key is None:\n",
        "    intervenable = load_intervenable_with_vanilla_intervention(\n",
        "        model,\n",
        "         ['block_output']*aggregate_n_layers,\n",
        "         list(range(inv_layer, layer+aggregate_n_layers)),\n",
        "         ['pos']*aggregate_n_layers,\n",
        "         num_unit=1\n",
        "      )\n",
        "  else:\n",
        "    intervenable = load_intervenable_with_vanilla_intervention(\n",
        "        model,\n",
        "        INTERVENTION_LOCATIONS[inv_location_key]['repr_type'],\n",
        "        INTERVENTION_LOCATIONS[inv_location_key]['layer'],\n",
        "        INTERVENTION_LOCATIONS[inv_location_key]['unit'],\n",
        "        INTERVENTION_LOCATIONS[inv_location_key]['num_unit'],\n",
        "      )\n",
        "else:\n",
        "  intervention_representations = 'block_output'\n",
        "  if 'mlp_output' in ckpt_name:\n",
        "    intervention_representations = 'mlp_output'\n",
        "  elif 'attention_output' in ckpt_name:\n",
        "    intervention_representations = 'attention_output'\n",
        "  intervenable = load_intervenable(\n",
        "      model,\n",
        "      ckpt_name.replace('.pt', '') + '.pt',\n",
        "      intervention_representations=intervention_representations)\n",
        "print('EVAL LAYER=%d POS=%s' % (inv_layer, inv_locs))\n",
        "split_to_eval_metrics = eval_with_interventions_batched(\n",
        "    intervenable, eval_split_to_dataset,\n",
        "    TEMPLATE_TO_INV_LOCATIONS,\n",
        "    tokenizer,\n",
        "    compute_metrics_fn=compute_logits_metrics if inference_mode == 'force_decode' else compute_metrics,\n",
        "    max_new_tokens=MAX_NEW_TOKENS,\n",
        "    max_input_length=INPUT_MAX_LEN,\n",
        "    debug_print=False,\n",
        "    eval_batch_size=16,\n",
        "    inference_mode=inference_mode,\n",
        "    )\n",
        "eval_metrics[f'{inv_layer}-{inv_locs[_BASE_TEMPLATE][0]}-{ckpt_name}-{inference_mode}-sample{len(verified_examples)}-{MAX_NEW_TOKENS}-{mode.split(\"_\")[0]}'] = split_to_eval_metrics\n",
        "remove_all_forward_hooks(model)\n",
        "del intervenable"
      ],
      "metadata": {
        "id": "OHPT-_N3AdJV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **[Run this block]**\n",
        "\n",
        "#@markdown Compute metrics\n",
        "\n",
        "#@markdown The AUC-ROC of fold 0 should be 0.763. Averaging the three folds should yield an AUC-ROC of **0.765**, which is 2 points higher than simply using confidence scores.\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "split_to_results = {}\n",
        "for key in eval_metrics:\n",
        "  split_to_iia = {}\n",
        "  for i, (split, metrics) in enumerate(sorted(eval_metrics[key].items(),\n",
        "                                            key=lambda x: x[1]['metrics']['labels']['accuracy'],\n",
        "                                            reverse=True)):\n",
        "    if 'loss' in metrics['metrics']['labels']['inv_outputs']:\n",
        "      split_to_iia[split] =  metrics['metrics']['labels']['inv_outputs']['loss_exp']\n",
        "    else:\n",
        "      split_to_iia[split] = metrics['metrics']['labels']['accuracy']\n",
        "  agg_logits = {k: split_to_iia[k] for k, v in split_to_iia.items()}\n",
        "  logits = np.array([agg_logits[k] for k in eval_metrics[key]])\n",
        "  labels = np.array([int('-correct-test' in k) for k in eval_metrics[key]])\n",
        "  print(f'Label: #positive={sum(labels)}  #negative={len(labels) - sum(labels)}')\n",
        "  split_to_results[key] = {'auc_roc': roc_auc_score(labels, logits),\n",
        "                           'iia': np.mean([v for k, v in split_to_iia.items() if k.endswith('-correct-test')])}\n",
        "  print(split_to_results[key]['auc_roc'], key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "Z0Aphmsy8WJ0",
        "outputId": "2580d988-8566-4584-b7b5-b57f0cd2ca5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: #positive=512  #negative=512\n",
            "0.7633495330810547 18-359-ood-prediction/models/mmlu-0_Meta-Llama-3-8B-Instruct-layer18-block_output-dim4-len256-posf_ep1_example1024.pt-force_decode-sample16-1-test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **[Run this block (Optional)]**\n",
        "\n",
        "#@markdown We can plot the IIA distribution for correct and wrong examples.\n",
        "\n",
        "#@markdown Examples where the target model predicted wrong generally have lower IIA, i.e., they do not share the same causal mechanisms as the correctly predicted examples.\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pred_data = pd.DataFrame([{'Correct': y, 'IIA': x}\n",
        "                          for x, y in zip(logits, labels)])\n",
        "sns.set_theme()\n",
        "\n",
        "ag = sns.displot(pred_data, x='IIA', hue='Correct', bins=20,\n",
        "                 palette=[sns.color_palette(\"Paired\")[9],\n",
        "                          sns.color_palette(\"Paired\")[1]])\n",
        "# set axis label font size to 24\n",
        "ag.set_xlabels('Interchange Intervention Accuracy', size=18)\n",
        "_ = ag.set_ylabels('Example Count', size=18)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "G-4itUThYFke",
        "outputId": "80f3bb3c-d934-4d3a-83f4-5f5b21416757",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 572.847x500 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method III: Correctness Probing"
      ],
      "metadata": {
        "id": "aL6_K1Ag1Fr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **[Run this block]**\n",
        "\n",
        "#@markdown Helper functions for training and evaluating probes.\n",
        "\n",
        "from probe import (\n",
        "    extract_all_hidden_states_batched,\n",
        "    train_linear_binary_classifier,\n",
        "    compute_auc_roc_for_all_locations\n",
        ")\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "LOCS = {\n",
        "  'mmlu_id': {\n",
        "    'loc_last_prompt': 1,\n",
        "    'loc_last_user_token': 1,\n",
        "    'loc_new_line': 1,\n",
        "    'causal_intermediate': 1,\n",
        "    'causal_output': 1,\n",
        "    'background_0': 2,\n",
        "    'background_1': 3,\n",
        "  },\n",
        "  'mmlu_ood-option-nato': {\n",
        "    'loc_last_prompt': 1,\n",
        "    'loc_last_user_token': 1,\n",
        "    'loc_new_line': 1,\n",
        "    'causal_intermediate': 1,\n",
        "    'causal_output': 1,\n",
        "    'background_0': 2,\n",
        "    'background_1': 3,\n",
        "  },\n",
        "  'mmlu_ood-option-e': {\n",
        "    'loc_last_prompt': 1,\n",
        "    'loc_last_user_token': 1,\n",
        "    'loc_new_line': 1,\n",
        "    'causal_intermediate': 1,\n",
        "    'causal_output': 1,\n",
        "    'background_0': 2,\n",
        "    'background_1': 3,\n",
        "  },\n",
        "}"
      ],
      "metadata": {
        "id": "vj_CwqDL_aSm",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **[Run this block]**\n",
        "\n",
        "import collections\n",
        "import gc\n",
        "import json\n",
        "\n",
        "\n",
        "FOLD_ID = '0'  #@param\n",
        "\n",
        "task_to_path = {\n",
        "    'mmlu': {\n",
        "        # Train\n",
        "        'id': os.path.join(DATA_DIR, 'mmlu_task', f'mmlu_Meta-Llama-3-8B-Instruct_no_chat_template_0shot_in_distribution_split_{FOLD_ID}.json'),\n",
        "        # Eval\n",
        "        'ood-option-nato': os.path.join(DATA_DIR, 'mmlu_task', f'mmlu_Meta-Llama-3-8B-Instruct_no_chat_template_0shot_ood-nato-label_split_{FOLD_ID}.json'),\n",
        "    }\n",
        "}\n",
        "method = 'lr'\n",
        "num_sample = {'train': 1024, 'val': 512, 'test': 512}\n",
        "input_max_length = 512\n",
        "\n",
        "for task in task_to_path:\n",
        "  TRAINVAL_SPLIT_KEY = f'{task}_id'\n",
        "  data_split = json.load(open(task_to_path[TRAINVAL_SPLIT_KEY.split('_')[0]]['id']))\n",
        "  split_to_layer_and_metrics = {}\n",
        "  for test_split in task_to_path[task]:\n",
        "    TEST_SPLIT_KEY = f'{task}_{test_split}'\n",
        "    print(task, TRAINVAL_SPLIT_KEY, TEST_SPLIT_KEY)\n",
        "    if 'ood' in TEST_SPLIT_KEY:\n",
        "      data_split['test'] = json.load(\n",
        "          open(task_to_path[TRAINVAL_SPLIT_KEY.split('_')[0]][TEST_SPLIT_KEY.split('_')[1]]))['test']\n",
        "    split_to_prompts = {\n",
        "        s: [p for t in data_split[s]\n",
        "              for p in data_split[s][t][:num_sample[s]]]\n",
        "        for s in data_split}\n",
        "    print(len(split_to_prompts['train']))\n",
        "    try:\n",
        "      del hidden_states['test']\n",
        "      del hidden_states['train']\n",
        "      del hidden_states['val']\n",
        "      del hidden_states\n",
        "    except:\n",
        "      pass\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    hidden_states = {\n",
        "        s: extract_all_hidden_states_batched(\n",
        "            model, tokenizer,\n",
        "            split_to_prompts[s], input_max_length,\n",
        "            token_positions={k: input_max_length - v\n",
        "                             for k, v in LOCS[TRAINVAL_SPLIT_KEY if s != 'test' else TEST_SPLIT_KEY].items()},\n",
        "            batch_size=64 if input_max_length < 64 else 4)\n",
        "        for s in split_to_prompts}\n",
        "    # Generate labels\n",
        "    example_labels = {\n",
        "        s: ['correct'] * len(data_split[s]['correct'][:num_sample[s]]) + ['wrong'] * len(data_split[s]['wrong'][:num_sample[s]])\n",
        "        for s in num_sample\n",
        "    }\n",
        "    # Train probes\n",
        "    split_type_to_metrics = compute_auc_roc_for_all_locations(hidden_states, example_labels, method)\n",
        "    split_to_layer_and_metrics[TEST_SPLIT_KEY] = split_type_to_metrics"
      ],
      "metadata": {
        "id": "Ip_vXkS_TmgE",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **[Run this block]**\n",
        "\n",
        "#@markdown The AUC-ROC of fold 0 should be 0.783 for the last token features (which happen to be causal features) and 0.743 for background features.\n",
        "\n",
        "#@markdown Averaging the three folds should yield an AUC-ROC of **0.769**, which is slightly higher (+0.04) than the counterfactual simulation results, while averaging background features yields a significantly lower AUC-ROC of 0.733.\n",
        "\n",
        "for loc in ['loc_last_prompt', 'loc_last_user_token', 'loc_new_line', 'causal_intermediate', 'causal_output', 'background_0', 'background_1']:\n",
        "  best_layer = sorted(split_to_layer_and_metrics['mmlu_id'], key=lambda layer: split_to_layer_and_metrics['mmlu_id'][layer][loc]['auc_roc'])[-1]\n",
        "  print(loc, best_layer)\n",
        "  for split in split_to_layer_and_metrics:\n",
        "    print(split, split_to_layer_and_metrics[split][best_layer][loc]['auc_roc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAGGFvQP3vSp",
        "outputId": "56ba9bb6-ec33-4449-c8c4-48a0f8147e0b",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loc_last_prompt 28\n",
            "mmlu_id 0.8136672973632812\n",
            "mmlu_ood-option-nato 0.7827377319335938\n",
            "loc_last_user_token 28\n",
            "mmlu_id 0.8136672973632812\n",
            "mmlu_ood-option-nato 0.7827377319335938\n",
            "loc_new_line 28\n",
            "mmlu_id 0.8136672973632812\n",
            "mmlu_ood-option-nato 0.7827377319335938\n",
            "causal_intermediate 28\n",
            "mmlu_id 0.8136672973632812\n",
            "mmlu_ood-option-nato 0.7827377319335938\n",
            "causal_output 28\n",
            "mmlu_id 0.8136672973632812\n",
            "mmlu_ood-option-nato 0.7827377319335938\n",
            "background_0 31\n",
            "mmlu_id 0.7776069641113281\n",
            "mmlu_ood-option-nato 0.7425880432128906\n",
            "background_1 17\n",
            "mmlu_id 0.7652931213378906\n",
            "mmlu_ood-option-nato 0.7298812866210938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method IV: Value Probing"
      ],
      "metadata": {
        "id": "lMq76Y_FD_dB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **[Run this block]**\n",
        "\n",
        "#@markdown Helper functions for parsing causal variable values\n",
        "\n",
        "model_output_path = \"ood-prediction/models/mmlu-0-id_Meta-Llama-3-8B-Instruct_prompt_to_topk_tokens.pt\"\n",
        "MMLU_ID_PROMPT_TO_OUTPUT = torch.load(model_output_path, map_location='cpu', weights_only=True)\n",
        "\n",
        "\n",
        "def mmlu_parse_variables(prompt):\n",
        "  def extract_prediction(topk_prob):\n",
        "    choices = ['A', 'B', 'C', 'D']\n",
        "    choice_to_prob = {}\n",
        "    for c in choices:\n",
        "      ans_dist = [x[1] for x in topk_prob if x[0].strip() == c]\n",
        "      choice_to_prob[c] = sum(ans_dist, 0)\n",
        "    return sorted(choice_to_prob, key=choice_to_prob.get, reverse=True)[0]\n",
        "  dist = MMLU_ID_PROMPT_TO_OUTPUT[prompt]\n",
        "  return {'label': extract_prediction(dist)}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8AIwViOJy3ZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **[Run this block]**\n",
        "\n",
        "#@markdown Now, we run value probing on the localized causal features.\n",
        "\n",
        "#@markdown The AUC-ROC of fold 0 should be around 0.771. Averaging the three folds should yield an AUC-ROC of **0.772**, which achieves the highest AUC-ROC among the four methods.\n",
        "\n",
        "import json\n",
        "import re\n",
        "\n",
        "from probe import (\n",
        "    extract_all_hidden_states_batched,\n",
        "    compute_auc_roc_for_all_locations\n",
        ")\n",
        "\n",
        "FOLD_ID = '0'  #@param\n",
        "eval_split = 'ood-nato-label'\n",
        "method = 'lr'\n",
        "num_sample = {'train': 1024, 'val': 512, 'test': 512}\n",
        "\n",
        "\n",
        "data_split = json.load(open(os.path.join(DATA_DIR, 'mmlu_task', f'mmlu_Meta-Llama-3-8B-Instruct_no_chat_template_0shot_in_distribution_split_{FOLD_ID}.json')))\n",
        "data_split['test'] = json.load(open(os.path.join(DATA_DIR, 'mmlu_task', f'mmlu_{model.name_or_path.split(\"/\")[-1]}_no_chat_template_0shot_{eval_split}_split_{FOLD_ID}.json')))['test']\n",
        "split_to_prompts = {\n",
        "    s: [p for t in data_split[s]\n",
        "          for p in data_split[s][t][:num_sample[s]]]\n",
        "    for s in data_split}\n",
        "\n",
        "ckpt_name = f'ood-prediction/models/mmlu-{FOLD_ID}_Meta-Llama-3-8B-Instruct-layer18-block_output-dim4-len256-posf_ep1_example1024.pt' #@param\n",
        "subspace = torch.load(ckpt_name)\n",
        "pos_key = 'causal_intermediate'\n",
        "\n",
        "input_max_length = 512\n",
        "layer = int(re.search(r'layer(\\d+)', ckpt_name).group(1))\n",
        "print('Using layer %d features.' % layer)\n",
        "pos = input_max_length - 1\n",
        "split_to_subspace_features = {}\n",
        "with torch.no_grad():\n",
        "  for s in split_to_prompts:\n",
        "    hidden_states = extract_all_hidden_states_batched(\n",
        "          model, tokenizer, split_to_prompts[s], input_max_length,\n",
        "          token_positions={pos_key: input_max_length - 1},\n",
        "          batch_size=64 if input_max_length < 64 else 4)\n",
        "    # B * Layer * D\n",
        "    subspace_features = hidden_states[pos_key][:, layer:layer+1, :] @ subspace[list(subspace.keys())[0]].T.detach().cpu().numpy()\n",
        "    split_to_subspace_features[s] = {pos_key: subspace_features}\n",
        "  # Generate labels\n",
        "  example_labels = {\n",
        "      s: [mmlu_parse_variables(x)['label'].split('|')[0]\n",
        "          for x in data_split[s]['correct'][:num_sample[s]]]\n",
        "      for s in ['train', 'val']\n",
        "  }\n",
        "  example_labels['test'] =  [t for t in data_split['test']\n",
        "                             for p in data_split['test'][t][:num_sample['test']]]\n",
        "  # Train probes\n",
        "  split_to_layer_and_metrics = compute_auc_roc_for_all_locations(\n",
        "      split_to_subspace_features, example_labels, method)\n",
        "print('Test set AUC-ROC:', split_to_layer_and_metrics[0][pos_key]['auc_roc'])"
      ],
      "metadata": {
        "id": "sYp9pCPWI-z4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf3d8cf-bfe7-4223-bb1a-7e704962db74",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using layer 18 features.\n",
            "4 ['C', 'A', 'B', 'D']\n",
            "0 causal_intermediate\n",
            "Training set accuracy: 0.9765625\n",
            "Validation set accuracy: 0.982421875\n",
            "Test set AUC-ROC: 0.7713356018066406\n"
          ]
        }
      ]
    }
  ]
}